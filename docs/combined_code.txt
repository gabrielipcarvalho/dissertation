
========================================
File: ../src/orchestration/orchestration-program.js
========================================

// File: src/orchestration/orchestration-program.js

// Import necessary libraries and adaptors
const {
	gpta, // GPTA function
} = require("../adaptors/gpta-adaptor");
const {
	gptb, // GPTB function
} = require("../adaptors/gptb-adaptor");
const {
	gptc, // GPTC function
} = require("../adaptors/gptc-adaptor");
const {
	gptd, // GPTD function
} = require("../adaptors/gptd-adaptor");
const path = require("path");
require("dotenv").config({ path: "../../config/.env" });

// Load the planner file
const plannerData = require(path.resolve(
	__dirname,
	"../../data/planner/planner.json"
));

// Orchestration function to coordinate adaptors
const orchestrateAdaptors = async () => {
	try {
		// Iterate over each entry in the planner
		for (const entry of plannerData) {
			const { position, daily } = entry;

			// Step 1: gpta() processes the news data
			await gpta(position);

			// Step 2: gptb() processes stock data and fetches gpta()'s results
			await gptb(position);

			// Step 3: gptc() analyzes the stock data
			await gptc(position);

			// Step 4: gptd() integrates predictions from gptb() and gptc()
			await gptd(position);

			console.log(
				`Orchestration completed for position ${position}, day ${daily}`
			);
		}
	} catch (error) {
		console.error("Error during orchestration:", error);
	}
};

// Execute the orchestration for all planner entries
(async () => {
	await orchestrateAdaptors();
})();

module.exports = { orchestrateAdaptors };


========================================
File: ../src/adaptors/gptc-adaptor.js
========================================

// File: src/adaptors/gptc-adaptor.js

const { OpenAI } = require("openai");
const fs = require("fs").promises;
const path = require("path");
require("dotenv").config({
	path: path.resolve(__dirname, "../../config/.env"),
});

// Configuration using GPTC's specific API key from the .env file
const openai = new OpenAI({
	apiKey: process.env.GPTC_API_KEY,
});

// Function to read and parse stock price data from JSON file
const readStockPriceData = async (day) => {
	const filePath = path.resolve(__dirname, "../../data/stock/daily_SPY.json");
	try {
		const stockData = JSON.parse(await fs.readFile(filePath, "utf8"));
		const dailyData = stockData["Time Series (Daily)"][day];
		if (!dailyData) {
			throw new Error(`Stock price data for ${day} not found`);
		}
		return dailyData;
	} catch (error) {
		console.error(
			`Error reading stock price data from file: ${filePath}`,
			error
		);
		throw error;
	}
};

// Function to analyze stock prices using GPT model and generate a prediction
const analyzeStockPricesWithGPT = async (stockPrices, currentDay) => {
	const prompt = `Analyze the following stock price data for trends and patterns, and make a concrete prediction for the next trading day. Clearly state whether stock prices are expected to rise or fall, and specify the expected percentage change or price range. Your prediction must be quantitative and actionable, enabling validation against actual market outcomes and also enabling fine-tuning. Consider historical trends, market behavior, and any notable anomalies in the data.

Prediction: Raise or Fall ?
How Much: Specify the expected percentage change (e.g., 5%, 1%, 0.5%)
Reasoning: Provide a concise explanation for the prediction, including relevant factors such as market trends, sentiment shifts, historical data, and any anomalies observed.

The stock price data to analyze is: ${JSON.stringify(stockPrices)}`;

	try {
		const completion = await openai.chat.completions.create({
			model: "gpt-3.5-turbo",
			messages: [
				{
					role: "system",
					content:
						"You are a financial analyst. Your task is to analyze the provided stock price data and make a concrete prediction about future stock price movements. Your prediction must be clear, quantitative, and actionable.",
				},
				{ role: "user", content: prompt },
			],
		});

		if (
			!completion ||
			!completion.choices ||
			completion.choices.length === 0
		) {
			console.error(
				"Invalid response from the API or missing data:",
				completion
			);
			throw new Error("Invalid response structure from API.");
		}

		const insights = completion.choices[0].message.content.trim();
		return insights;
	} catch (error) {
		console.error(
			"Error during GPT model analysis of stock prices:",
			error
		);
		throw error;
	}
};

// Function to log the GPTC results to a JSON file
const logGptcResults = async (position, day, prediction) => {
	console.log(
		`Logging GPTC prediction results for position ${position}, day ${day}...`
	);
	const logFilePath = path.resolve(
		__dirname,
		"../../data/logs/gptc.logs.json"
	);

	// Read existing log data
	let logData = [];
	try {
		const logFileContents = await fs.readFile(logFilePath, "utf8");
		if (logFileContents.trim()) {
			logData = JSON.parse(logFileContents);
		} else {
			console.log("Log file is empty, starting with a new log file.");
		}
	} catch (error) {
		if (error.code === "ENOENT") {
			console.log("Log file not found, creating a new one.");
		} else if (error instanceof SyntaxError) {
			console.error(
				"Log file is malformed, starting with a new log file."
			);
		} else {
			throw error;
		}
	}

	// Append the new log entry
	logData.push({
		position: position,
		"current day": day,
		data: {
			prediction,
		},
	});

	// Write the updated log data back to the file
	await fs.writeFile(logFilePath, JSON.stringify(logData, null, 2), {
		encoding: "utf8",
	});
	console.log(
		`Prediction results logged successfully for position ${position}, day ${day}.`
	);
};

// Main GPTC function
const gptc = async (position) => {
	try {
		console.log(`Starting GPTC processing for position ${position}...`);

		// Load the planner file and get the corresponding daily entry for the position
		const plannerPath = path.resolve(
			__dirname,
			"../../data/planner/planner.json"
		);
		const plannerData = JSON.parse(await fs.readFile(plannerPath, "utf8"));
		const entry = plannerData.find((item) => item.position === position);

		if (!entry || !entry.daily) {
			throw new Error(`No daily entry found for position ${position}`);
		}

		const day = entry.daily;
		const stockPrices = await readStockPriceData(day);
		const prediction = await analyzeStockPricesWithGPT(stockPrices, day);

		await logGptcResults(position, day, prediction);

		console.log(`GPTC processing completed for position ${position}.`);
	} catch (error) {
		console.error(`Error in GPTC for position ${position}:`, error);
		throw error;
	}
};

module.exports = {
	gptc,
};


========================================
File: ../src/adaptors/gptd-adaptor.js
========================================

// File: src/adaptors/gptd-adaptor.js

const { OpenAI } = require("openai");
const fs = require("fs").promises;
const path = require("path");
require("dotenv").config({
	path: path.resolve(__dirname, "../../config/.env"),
});

// Configuration using GPTD's specific API key from the .env file
const openai = new OpenAI({
	apiKey: process.env.GPTD_API_KEY,
});

// Function to read JSON data from a file
const readJSONData = async (filePath) => {
	try {
		const dataJson = await fs.readFile(filePath, { encoding: "utf8" });
		return JSON.parse(dataJson);
	} catch (error) {
		console.error(`Error reading JSON file: ${filePath}`, error);
		throw error;
	}
};

// Function to log data to JSON file
const logDataToFile = async (filePath, data) => {
	let logData = [];
	try {
		// Attempt to read the log file
		const logFileContents = await fs.readFile(filePath, "utf8");
		if (logFileContents.trim()) {
			logData = JSON.parse(logFileContents);
		} else {
			console.log("Log file is empty, starting with a new log file.");
		}
	} catch (error) {
		if (error.code === "ENOENT") {
			console.log("Log file not found, creating a new one.");
		} else if (error instanceof SyntaxError) {
			console.error(
				"Log file is malformed, starting with a new log file."
			);
		} else {
			throw error;
		}
	}

	// Append the new log entry
	logData.push(data);

	// Write the updated log data back to the file
	await fs.writeFile(filePath, JSON.stringify(logData, null, 2), {
		encoding: "utf8",
	});
	console.log(`Data logged successfully to ${filePath}.`);
};

// Function to fetch prediction data from logs
const fetchPredictionData = async (position, filePath) => {
	const logData = await readJSONData(filePath);
	const entry = logData.find((item) => item.position === position);
	if (!entry) {
		throw new Error(
			`No entry found for position ${position} in ${filePath}`
		);
	}
	return entry.data.prediction;
};

// Function to integrate and analyze predictions from GPTB and GPTC
const integrateAndAnalyzePredictions = async (position, currentDay) => {
	try {
		const gptbLogsPath = path.resolve(
			__dirname,
			"../../data/logs/gptb.logs.json"
		);
		const gptcLogsPath = path.resolve(
			__dirname,
			"../../data/logs/gptc.logs.json"
		);

		const gptbPrediction = await fetchPredictionData(
			position,
			gptbLogsPath
		);
		const gptcPrediction = await fetchPredictionData(
			position,
			gptcLogsPath
		);

		const prompt = `Integrate and analyze predictions from GPTB and GPTC for Day ${currentDay}, assessing the alignment and discrepancies between the two forecasts. Ensure the analysis highlights key points of agreement and divergence between the models, providing a comprehensive understanding of their predictions. Predictions from GPTB: ${gptbPrediction}, Predictions from GPTC: ${gptcPrediction}.`;

		const completion = await openai.chat.completions.create({
			model: "gpt-3.5-turbo",
			messages: [
				{
					role: "system",
					content:
						"Synthesize the information from GPTB and GPTC models to provide a cohesive analysis. Your analysis should integrate insights from both models, highlighting areas of agreement and divergence, and explain the implications for stock price movements. Ensure the analysis is detailed and includes quantitative assessments where possible.",
				},
				{
					role: "user",
					content: prompt,
				},
			],
		});

		if (
			!completion ||
			!completion.choices ||
			completion.choices.length === 0
		) {
			throw new Error("Invalid response structure from API.");
		}

		const combinedAnalysis = completion.choices[0].message.content.trim();
		const logData = {
			position: position,
			"current day": currentDay,
			data: {
				analysis: combinedAnalysis,
			},
		};

		const gptdLogsPath = path.resolve(
			__dirname,
			"../../data/logs/gptd.logs.json"
		);
		await logDataToFile(gptdLogsPath, logData);

		return combinedAnalysis;
	} catch (error) {
		console.error(
			"Error during integration and analysis of predictions:",
			error
		);
		throw error;
	}
};

// Function to make a final prediction for the next trading day stock prices
const makeFinalPrediction = async (position, currentDay) => {
	try {
		const gptdLogsPath = path.resolve(
			__dirname,
			"../../data/logs/gptd.logs.json"
		);
		const logData = await readJSONData(gptdLogsPath);
		const entry = logData.find(
			(item) =>
				item.position === position && item["current day"] === currentDay
		);

		if (!entry) {
			throw new Error(
				`No analysis data found for position ${position} and day ${currentDay} in GPTD logs.`
			);
		}

		const analysisData = entry.data.analysis;
		const nextDay = `day${parseInt(currentDay.replace("day", "")) + 1}`;

		const prompt = `Based on the integrated analysis from Day ${currentDay}, synthesize insights to make a final, comprehensive prediction for ${nextDay} stock prices. Your prediction should clearly state whether stock prices are expected to rise or fall, by how much, and the reasoning behind your forecast. Ensure the prediction is quantitative, specifying the expected percentage change or price range. Consider historical trends, recent market behaviour, and any notable anomalies in the data. Ensure that the prediction is quantitative and precise, with a clear percentage and a solid reasoning behind the forecast. The prediction must be actionable and suitable for further validation and fine-tuning.

Prediction: Raise or Fall ?
How Much: Specify the expected percentage change (e.g., 5%, 1%, 0.5%)
Reasoning: Provide a concise explanation for the prediction, including relevant factors such as market trends, sentiment shifts, historical data, and any anomalies observed. Analysis data: ${analysisData}.`;

		const completion = await openai.chat.completions.create({
			model: "gpt-3.5-turbo",
			messages: [
				{
					role: "system",
					content:
						"Provide a detailed forecast using the integrated analysis from GPTB and GPTC. Your forecast should clearly state whether stock prices will rise or fall, by how much, and include the reasoning behind your prediction. Ensure the forecast is actionable and precise, enabling validation against actual market outcomes.",
				},
				{
					role: "user",
					content: prompt,
				},
			],
		});

		if (
			!completion ||
			!completion.choices ||
			completion.choices.length === 0
		) {
			throw new Error("Invalid response structure from API.");
		}

		const finalPrediction = completion.choices[0].message.content.trim();
		const logDataEntry = {
			position: position,
			"current day": nextDay,
			data: {
				prediction: finalPrediction,
			},
		};

		await logDataToFile(gptdLogsPath, logDataEntry);

		return finalPrediction;
	} catch (error) {
		console.error("Error making final prediction for stock prices:", error);
		throw error;
	}
};

// Main GPTD function to integrate analysis and make predictions
const gptd = async (position) => {
	try {
		console.log(`Starting GPTD processing for position ${position}...`);

		// Load the planner file and get the corresponding daily entry for the position
		const plannerPath = path.resolve(
			__dirname,
			"../../data/planner/planner.json"
		);
		const plannerData = JSON.parse(await fs.readFile(plannerPath, "utf8"));
		const entry = plannerData.find((item) => item.position === position);

		if (!entry || !entry.daily) {
			throw new Error(`No daily entry found for position ${position}`);
		}

		const currentDay = entry.daily;

		// Integrate and analyze predictions from GPTB and GPTC
		await integrateAndAnalyzePredictions(position, currentDay);

		// Make final prediction for the next trading day stock prices
		await makeFinalPrediction(position, currentDay);

		console.log(`GPTD processing completed for position ${position}.`);
	} catch (error) {
		console.error(`Error in GPTD for position ${position}:`, error);
		throw error;
	}
};

module.exports = {
	gptd,
};


========================================
File: ../src/adaptors/gpta-adaptor.js
========================================

// File: src/adaptors/gpta-adaptor.js

// Import necessary libraries
const { OpenAI } = require("openai");
const fs = require("fs").promises;
const path = require("path");
require("dotenv").config({
	path: path.resolve(__dirname, "../../config/.env"),
});
const ProgressBar = require("progress");

// Configuration using GPTA's specific API key from the .env file
const openai = new OpenAI({
	apiKey: process.env.GPTA_API_KEY,
});

// Function to load the planner file and find the corresponding news entries for a given position
const getNewsForPosition = async (position) => {
	console.log(
		`Loading planner file to find news entries for position ${position}...`
	);
	const plannerPath = path.resolve(
		__dirname,
		"../../data/planner/planner.json"
	);
	const plannerData = JSON.parse(await fs.readFile(plannerPath, "utf8"));
	const entry = plannerData.find((item) => item.position === position);

	if (!entry || !entry.news) {
		throw new Error(`No news found for position ${position}`);
	}

	console.log(`Found news entries for position ${position}: ${entry.news}`);
	return entry.news.split(", ").map((newsId) => newsId.trim());
};

// Function to fetch news data for a given news ID from news.json
const fetchNewsData = async (newsId) => {
	console.log(`Fetching news data for ${newsId}...`);
	const newsPath = path.resolve(__dirname, "../../data/news/news.json");
	const allNewsData = JSON.parse(await fs.readFile(newsPath, "utf8"));

	if (!allNewsData[newsId]) {
		throw new Error(`News data for ${newsId} not found`);
	}

	// Extract relevant parts from the news object and concatenate them
	const newsArticles = allNewsData[newsId];
	console.log(`Fetched ${newsArticles.length} articles for ${newsId}`);
	return newsArticles
		.map((article) => `${article.title}\n\n${article.body}`)
		.join("\n\n");
};

// Function to extract key information using GPT
const extractKeyInformation = async (newsData) => {
	console.log("Extracting key information from news data...");

	const completion = await openai.chat.completions.create({
		model: "gpt-3.5-turbo",
		messages: [
			{
				role: "system",
				content:
					"Please analyse the following text and extract key information that could significantly impact stock market trends. Focus on identifying critical details related to corporate earnings, economic announcements, geopolitical events, market forecasts, and other influential factors. Ensure the summary is concise and highlights the potential market implications of each identified element.",
			},
			{
				role: "user",
				content: newsData,
			},
		],
	});

	if (!completion || !completion.choices || completion.choices.length === 0) {
		throw new Error("Invalid response structure from API.");
	}

	const extractedInformation = completion.choices[0].message.content.trim();

	console.log("Completed extraction of key information.");
	return extractedInformation;
};

// Function to perform sentiment analysis using GPT
const performSentimentAnalysis = async (keyInformation) => {
	console.log("Performing sentiment analysis on key information...");
	const completion = await openai.chat.completions.create({
		model: "gpt-3.5-turbo",
		messages: [
			{
				role: "system",
				content:
					"Utilise the provided information to perform a comprehensive sentiment analysis, determining the overall sentiment (positive, negative, or neutral) and its intensity. Focus on how this sentiment might affect stock market trends, considering the potential impact on market movements, investor behaviour, and future market forecasts. Provide a detailed explanation of your analysis and its implications for stock market trends.",
			},
			{
				role: "user",
				content: keyInformation,
			},
		],
	});

	if (!completion || !completion.choices || completion.choices.length === 0) {
		throw new Error("Invalid response structure from API.");
	}

	console.log("Completed sentiment analysis.");
	return completion.choices[0].message.content.trim();
};

// Function to log the results to the gpta.logs.json file
const logResults = async (
	position,
	currentDay,
	keyInformation,
	sentimentAnalysis
) => {
	console.log(
		`Logging results for position ${position}, day ${currentDay}...`
	);
	const logFilePath = path.resolve(
		__dirname,
		"../../data/logs/gpta.logs.json"
	);

	// Read existing log data
	let logData = [];
	try {
		// Attempt to read the log file
		const logFileContents = await fs.readFile(logFilePath, "utf8");

		// If the log file is not empty, parse it
		if (logFileContents.trim()) {
			logData = JSON.parse(logFileContents);
		} else {
			console.log("Log file is empty, starting with a new log file.");
		}
	} catch (error) {
		if (error.code === "ENOENT") {
			// File does not exist, this is fine and we will start with an empty array
			console.log("Log file not found, creating a new one.");
		} else if (error instanceof SyntaxError) {
			// JSON is malformed, log this error
			console.error(
				"Log file is malformed, starting with a new log file."
			);
		} else {
			throw error; // Throw any error that is not related to file existence or JSON parsing
		}
	}

	// Append the new log entry
	logData.push({
		position: position,
		"current day": currentDay,
		data: {
			"key information": keyInformation,
			"sentiment analysis": sentimentAnalysis,
		},
	});

	// Write the updated log data back to the file
	await fs.writeFile(logFilePath, JSON.stringify(logData, null, 2), {
		encoding: "utf8",
	});
	console.log(
		`Results logged successfully for position ${position}, day ${currentDay}.`
	);
};

// Main GPTA function
const gpta = async (position) => {
	try {
		console.log(`Starting GPTA processing for position ${position}...`);
		const newsIds = await getNewsForPosition(position);

		for (const newsId of newsIds) {
			const newsData = await fetchNewsData(newsId);
			const keyInformation = await extractKeyInformation(newsData);
			const sentimentAnalysis = await performSentimentAnalysis(
				keyInformation
			);

			await logResults(
				position,
				newsId,
				keyInformation,
				sentimentAnalysis
			);
			console.log(
				`GPTA processed news for ${newsId} at position ${position}`
			);
		}

		console.log(`GPTA completed processing for position ${position}.`);
	} catch (error) {
		console.error(`Error in GPTA for position ${position}:`, error);
		throw error;
	}
};

module.exports = {
	gpta,
};


========================================
File: ../src/adaptors/gptb-adaptor.js
========================================

// File: src/adaptors/gptb-adaptor.js

// Import necessary libraries
const { OpenAI } = require("openai");
const fs = require("fs").promises;
const path = require("path");
require("dotenv").config({
	path: path.resolve(__dirname, "../../config/.env"),
});
const ProgressBar = require("progress");

// Configuration using GPTB's specific API key from the .env file
const openai = new OpenAI({
	apiKey: process.env.GPTB_API_KEY,
});

// Function to load the planner file and find the corresponding daily entry for a given position
const getDailyForPosition = async (position) => {
	console.log(
		`Loading planner file to find daily entry for position ${position}...`
	);
	const plannerPath = path.resolve(
		__dirname,
		"../../data/planner/planner.json"
	);
	const plannerData = JSON.parse(await fs.readFile(plannerPath, "utf8"));
	const entry = plannerData.find((item) => item.position === position);

	if (!entry || !entry.daily) {
		throw new Error(`No daily entry found for position ${position}`);
	}

	console.log(`Found daily entry for position ${position}: ${entry.daily}`);
	return entry.daily;
};

// Function to fetch stock price data for a given day from daily_SPY.json
const fetchStockPriceData = async (day) => {
	console.log(`Fetching stock price data for ${day}...`);
	const stockPath = path.resolve(
		__dirname,
		"../../data/stock/daily_SPY.json"
	);
	const stockData = JSON.parse(await fs.readFile(stockPath, "utf8"));

	const dailyData = stockData["Time Series (Daily)"][day];
	if (!dailyData) {
		throw new Error(`Stock price data for ${day} not found`);
	}

	console.log(`Fetched stock price data for ${day}`);
	return dailyData;
};

// Function to fetch sentiment analysis from gpta.logs.json for a given position
const fetchSentimentAnalysis = async (position) => {
	console.log(`Fetching sentiment analysis for position ${position}...`);
	const logPath = path.resolve(__dirname, "../../data/logs/gpta.logs.json");
	const logData = JSON.parse(await fs.readFile(logPath, "utf8"));

	const filteredLogs = logData.filter((entry) => entry.position === position);

	if (filteredLogs.length === 0) {
		throw new Error(`No GPTA logs found for position ${position}`);
	}

	const sentimentAnalysis = filteredLogs.map((entry) => ({
		sentimentAnalysis: entry.data["sentiment analysis"],
		currentDay: entry["current day"],
	}));

	console.log(`Fetched sentiment analysis for position ${position}`);
	return sentimentAnalysis;
};

// Function to analyze how sentiment and stock prices affected market trends
const analyzeImpactOnStockPrices = async (
	sentimentAnalysis,
	stockPrices,
	day
) => {
	console.log(`Analyzing impact on stock prices for ${day}...`);

	const prompt = `Utilise the following data to conduct a comprehensive analysis of how these factors might influence stock price movements for ${day}. Focus on the sentiment analysis and the corresponding stock price data. Your analysis should cover the following aspects in detail:

1. **Relevance to Stock Prices**: Identify and explain the direct relevance of the sentiment to stock market trends.

2. **Sentiment Influence**: Analyse how the sentiment (positive, negative, neutral) correlates with observed or potential stock price movements.

3. **Causative Links**: Establish and explain any causative links between the news sentiment and stock price fluctuations.

4. **Comparative Analysis**: Compare the impact of the current day's sentiment with data from previous days.

5. **Potential Anomalies or Exceptions**: Identify and explain any anomalies where the expected impact of sentiment did not align with actual stock price movements.

Provide a detailed and structured analysis, incorporating quantitative and qualitative insights to support your conclusions.`;

	const combinedData = JSON.stringify({
		sentimentAnalysis,
		stockPrices,
	});

	const completion = await openai.chat.completions.create({
		model: "gpt-3.5-turbo",
		messages: [
			{ role: "system", content: prompt },
			{ role: "user", content: combinedData },
		],
	});

	if (!completion || !completion.choices || completion.choices.length === 0) {
		throw new Error("Invalid response structure from API.");
	}

	const analysisResult = completion.choices[0].message.content.trim();

	console.log("Completed analysis of impact on stock prices.");
	return analysisResult;
};

// Function to log analysis results to gptb.logs.json
const logAnalysisResults = async (position, day, analysis) => {
	console.log(
		`Logging analysis results for position ${position}, day ${day}...`
	);
	const logPath = path.resolve(__dirname, "../../data/logs/gptb.logs.json");

	// Read existing log data
	let logData = [];
	try {
		const logFileContents = await fs.readFile(logPath, "utf8");
		if (logFileContents.trim()) {
			logData = JSON.parse(logFileContents);
		} else {
			console.log("Log file is empty, starting with a new log file.");
		}
	} catch (error) {
		if (error.code === "ENOENT") {
			console.log("Log file not found, creating a new one.");
		} else if (error instanceof SyntaxError) {
			console.error(
				"Log file is malformed, starting with a new log file."
			);
		} else {
			throw error;
		}
	}

	// Append the new log entry
	logData.push({
		position: position,
		"current day": day,
		data: {
			analysis,
		},
	});

	// Write the updated log data back to the file
	await fs.writeFile(logPath, JSON.stringify(logData, null, 2), {
		encoding: "utf8",
	});
	console.log(
		`Analysis results logged successfully for position ${position}, day ${day}.`
	);
};

// Function to predict future stock prices based on the analysis
const predictStockPrices = async (analysis, currentDay) => {
	const nextDay = `day${parseInt(currentDay.replace("day", "")) + 1}`;
	console.log(`Predicting stock prices for ${nextDay}...`);

	const prompt = `Using the analysis of sentiment impact and market sentiment from ${currentDay}, forecast the stock prices for ${nextDay}. Please provide the prediction in the following format:

Prediction: Raise or Fall ?
How Much: Specify the expected percentage change (e.g., 5%, 1%, 0.5%)
Reasoning: Provide a concise explanation for the prediction, including relevant factors such as market trends, sentiment shifts, historical data, and any anomalies observed.

Ensure that the prediction is quantitative and precise, with a clear percentage change and a solid reasoning behind the forecast. The prediction must be actionable and suitable for further validation and fine-tuning.`;

	const completion = await openai.chat.completions.create({
		model: "gpt-3.5-turbo",
		messages: [
			{ role: "system", content: prompt },
			{ role: "user", content: analysis },
		],
	});

	if (!completion || !completion.choices || completion.choices.length === 0) {
		throw new Error("Invalid response structure from API.");
	}

	const prediction = completion.choices[0].message.content.trim();
	console.log(`Stock price prediction for ${nextDay} completed.`);
	return prediction;
};

// Function to log prediction results to gptb.logs.json
const logPredictionResults = async (position, day, prediction) => {
	console.log(
		`Logging prediction results for position ${position}, day ${day}...`
	);
	const logPath = path.resolve(__dirname, "../../data/logs/gptb.logs.json");

	// Read existing log data
	let logData = [];
	try {
		const logFileContents = await fs.readFile(logPath, "utf8");
		if (logFileContents.trim()) {
			logData = JSON.parse(logFileContents);
		} else {
			console.log("Log file is empty, starting with a new log file.");
		}
	} catch (error) {
		if (error.code === "ENOENT") {
			console.log("Log file not found, creating a new one.");
		} else if (error instanceof SyntaxError) {
			console.error(
				"Log file is malformed, starting with a new log file."
			);
		} else {
			throw error;
		}
	}

	// Find the entry for the current day and update it with the prediction
	const entryIndex = logData.findIndex(
		(entry) => entry.position === position && entry["current day"] === day
	);

	if (entryIndex !== -1) {
		logData[entryIndex].data.prediction = prediction;
	} else {
		logData.push({
			position: position,
			"current day": day,
			data: {
				prediction,
			},
		});
	}

	// Write the updated log data back to the file
	await fs.writeFile(logPath, JSON.stringify(logData, null, 2), {
		encoding: "utf8",
	});
	console.log(
		`Prediction results logged successfully for position ${position}, day ${day}.`
	);
};

// Function to handle the entire GPTB processing
const gptb = async (position) => {
	try {
		console.log(`Starting GPTB processing for position ${position}...`);

		const day = await getDailyForPosition(position);
		const stockPrices = await fetchStockPriceData(day);
		const sentimentAnalysis = await fetchSentimentAnalysis(position);

		const analysis = await analyzeImpactOnStockPrices(
			sentimentAnalysis,
			stockPrices,
			day
		);
		await logAnalysisResults(position, day, analysis);

		const prediction = await predictStockPrices(analysis, day);
		await logPredictionResults(position, day, prediction);

		console.log(`GPTB processing completed for position ${position}.`);
	} catch (error) {
		console.error(`Error in GPTB for position ${position}:`, error);
		throw error;
	}
};

// Export the gptb function so it can be used in other files
module.exports = {
	gptb,
};


========================================
File: ./scripts/combine_code_script.py
========================================

# File: scripts/combine_code_script.py

import os

# Define the directories and file extensions to include
directories_to_include = [
    # "../scripts",
    "../src/orchestration",
    "../src/adaptors",
    # "../src/news_fetch",
    # "../src/planner",
    # "../src/stock_fetch"
]
extensions_to_include = ['.py', '.js']

# Define the output file path
output_file_path = '../docs/combined_code.txt'

# Start writing to the output file
with open(output_file_path, 'w') as output_file:
    for directory in directories_to_include:
        for root, _, files in os.walk(directory):
            for fil in files:
                if any(fil.endswith(ext) for ext in extensions_to_include):
                    file_path = os.path.join(root, fil)
                    output_file.write(f"\n{'='*40}\n")
                    output_file.write(f"File: {file_path}\n")
                    output_file.write(f"{'='*40}\n\n")
                    with open(file_path, 'r') as f:
                        output_file.write(f.read())
                        output_file.write("\n")

    # Include this script's code at the end of the file
    script_path = './scripts/combine_code_script.py'
    output_file.write(f"\n{'='*40}\n")
    output_file.write(f"File: {script_path}\n")
    output_file.write(f"{'='*40}\n\n")
    with open(__file__, 'r') as f:
        output_file.write(f.read())
        output_file.write("\n")

print(f"All code has been combined into {output_file_path}")
